{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deepgram Live Transcription API Demo\n",
    "\n",
    "This is a demonstration of the live transcription API offered by Deepgram, using their in-house Nova-2 model. You can use this notebook to transcribe live audio using your device's microphone input or a streaming audio from the Internet, using a websocket connection with Deepgram's API server.\n",
    "\n",
    "Transcribing from a microphone will unfortunately only work on your local machine, and with macOS or linux as it requires portaudio.\n",
    "\n",
    "Speaker diarization is not available for live transcription.\n",
    "\n",
    "The radio streaming function by running the notebook on JupyterLab / Vertex AI workbench. There are some display issues on Colab unfortunately.\n",
    "\n",
    "Running the service requires credits for Deepgram API (provided by a trial account). Please get in touch with @yaufai.chau on Slack if credits runs out or you have futher enquiries.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# Uncomment the line below to install portaudio on macOS\n",
    "!brew install portaudio\n",
    "\n",
    "# Uncomment the lines below install portaudio on Linux\n",
    "# !sudo apt-get install portaudio19-dev\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install deepgram-sdk httpx ipywidgets pyaudio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "API Key and imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from deepgram import (\n",
    "    DeepgramClient,\n",
    "    LiveTranscriptionEvents,\n",
    "    LiveOptions,\n",
    "    Microphone,\n",
    ")\n",
    "import httpx\n",
    "from IPython.display import display, HTML, Markdown\n",
    "import threading\n",
    "import ipywidgets as widgets\n",
    "import time\n",
    "\n",
    "# Please create your own free API key at https://console.deepgram.com/signup\n",
    "DEEPGRAM_API_KEY = \"YOUR_DEEPGRAM_API_KEY\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main transcription code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_finals = []\n",
    "def live_transcription(streaming_url=None):\n",
    "    global is_finals\n",
    "    try:\n",
    "        deepgram = DeepgramClient(DEEPGRAM_API_KEY)\n",
    "        dg_connection = deepgram.listen.websocket.v('1')\n",
    "        stop_event = threading.Event()\n",
    "        \n",
    "        def on_open(self, open, **kwargs):\n",
    "            print(\"Connection Open\")\n",
    "            \n",
    "        def on_message_mic(self, result, **kwargs):\n",
    "            global is_finals\n",
    "            sentence = result.channel.alternatives[0].transcript\n",
    "            if len(sentence) == 0:\n",
    "                return\n",
    "            if result.is_final:\n",
    "                is_finals.append(sentence)\n",
    "                if result.speech_final:\n",
    "                    utterance = \" \".join(is_finals)\n",
    "                    display(Markdown(f'**Transcript:** {utterance}'))\n",
    "                    is_finals = []\n",
    "\n",
    "        def on_message_radio_stream(self, result, **kwargs):\n",
    "            global is_finals\n",
    "            sentence = result.channel.alternatives[0].transcript\n",
    "            if len(sentence) == 0:\n",
    "                return\n",
    "            else:\n",
    "                display(Markdown(f'**Transcript:** {sentence}'))\n",
    "                time.sleep(RADIO_TRANSCRIPT_INTERVAL)\n",
    "\n",
    "        def on_metadata(self, metadata, **kwargs):\n",
    "            print(f\"Metadata: {metadata}\")\n",
    "\n",
    "        def on_speech_started(self, speech_started, **kwargs):\n",
    "            print(\"Speech Started\")\n",
    "\n",
    "        def on_utterance_end(self, utterance_end, **kwargs):\n",
    "            global is_finals\n",
    "            # print(\"Utterance End\")\n",
    "            if len(is_finals) > 0:\n",
    "                utterance = \" \".join(is_finals)\n",
    "                # print(f\"Utterance End: {utterance}\")\n",
    "                display(Markdown(f'**Transcript:** {utterance}'))\n",
    "                is_finals = []\n",
    "\n",
    "        def on_close(self, close, **kwargs):\n",
    "            print(\"Connection Closed\")\n",
    "\n",
    "        def on_error(self, error, **kwargs):\n",
    "            print(f\"Handled Error: {error}\")\n",
    "\n",
    "        def on_unhandled(self, unhandled, **kwargs):\n",
    "            print(f\"Unhandled Websocket Message: {unhandled}\")\n",
    "\n",
    "        # dg_connection.on(LiveTranscriptionEvents.Open, on_open)\n",
    "        # dg_connection.on(LiveTranscriptionEvents.Metadata, on_metadata)\n",
    "        # dg_connection.on(LiveTranscriptionEvents.SpeechStarted, on_speech_started)\n",
    "\n",
    "        # dg_connection.on(LiveTranscriptionEvents.Close, on_close)\n",
    "        dg_connection.on(LiveTranscriptionEvents.Error, on_error)\n",
    "        dg_connection.on(LiveTranscriptionEvents.Unhandled, on_unhandled)\n",
    "\n",
    "        # Shared options for radio or microphone transcription\n",
    "        options: LiveOptions = LiveOptions(\n",
    "            model=\"nova-2\",\n",
    "            language=\"en-US\",\n",
    "            smart_format=True,)\n",
    "\n",
    "        if streaming_url:\n",
    "            # Send streaming audio from the URL to Deepgram\n",
    "            # Define output format for radio streaming transcription\n",
    "            dg_connection.on(LiveTranscriptionEvents.Transcript, on_message_radio_stream)\n",
    "\n",
    "            def stream_audio_url():\n",
    "                print(\"Audio stream started...\")\n",
    "                with httpx.stream('GET', streaming_url) as r:\n",
    "                    for data in r.iter_bytes():\n",
    "                        if stop_event.is_set():\n",
    "                            break\n",
    "                        dg_connection.send(data)\n",
    "                print(\"Audio stream thread stopping...\")\n",
    "\n",
    "            audio_thread = threading.Thread(target=stream_audio_url)\n",
    "        else:\n",
    "            # Send streaming audio from the microphone to Deepgram\n",
    "            # Define output format for microphone transcription\n",
    "            dg_connection.on(LiveTranscriptionEvents.Transcript, on_message_mic)\n",
    "            dg_connection.on(LiveTranscriptionEvents.UtteranceEnd, on_utterance_end)\n",
    "\n",
    "            # Additional options for microphone transcription\n",
    "            additional_options = {\n",
    "                \"encoding\": \"linear16\",\n",
    "                \"channels\": 1,\n",
    "                \"sample_rate\": 16000,\n",
    "                \"interim_results\": True,\n",
    "                \"utterance_end_ms\": \"1000\",\n",
    "                \"vad_events\": True,\n",
    "                \"endpointing\": 100,\n",
    "            }\n",
    "\n",
    "            for key, value in additional_options.items():\n",
    "                setattr(options, key, value)\n",
    "\n",
    "            def stream_audio_mic():\n",
    "                print(\"Mic stream started...\")\n",
    "                # Open a microphone stream on the default input device\n",
    "                microphone = Microphone(dg_connection.send)\n",
    "                microphone.start()\n",
    "                while not stop_event.is_set():\n",
    "                    time.sleep(0.1)\n",
    "                microphone.finish()\n",
    "                print(\"Mic stream thread stopping...\")\n",
    "\n",
    "            audio_thread = threading.Thread(target=stream_audio_mic)\n",
    "        \n",
    "        dg_connection.start(options)\n",
    "        audio_thread.start()\n",
    "\n",
    "        # Create a button to stop transcription\n",
    "        stop_button = widgets.Button(\n",
    "            description='Stop Transcription',\n",
    "            disabled=False,\n",
    "            button_style='',  # 'success', 'info', 'warning', 'danger' or ''\n",
    "            tooltip='Click to stop transcription',\n",
    "            icon='stop'  # (FontAwesome names without the `fa-` prefix)\n",
    "        )\n",
    "        display(stop_button)\n",
    "\n",
    "        def on_button_click(b):\n",
    "            stop_event.set()  # Signal all threads to stop\n",
    "            stop_button.description = \"Stopping...\"\n",
    "            stop_button.disabled = True\n",
    "            audio_thread.join()\n",
    "            dg_connection.finish()\n",
    "            print('Finished')\n",
    "            stop_button.description = \"Stopped\"\n",
    "\n",
    "        stop_button.on_click(on_button_click)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f'Error occurred: {e}')\n",
    "        return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the cell and press the Live transcribe button to transcribe microphone input  \n",
    "(Requies running the notebook to your local laptop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de62ee02a1784f179292998440c3ca52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(button_style='info', description='Live transcribe', icon='play', style=ButtonStyle(), tooltip='Click to…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mic stream started...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "acb81e9d58e0488e97806a39958fff41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Stop Transcription', icon='stop', style=ButtonStyle(), tooltip='Click to stop transcriptio…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Transcript:** Hello. This is a test of the live transcription capability of Deepgram API. You can transcribe your live voice or a radio stream"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Transcript:** using this API service"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mic stream thread stopping...\n",
      "Finished\n"
     ]
    }
   ],
   "source": [
    "# Create a button to start mic transcription\n",
    "start_button = widgets.Button(\n",
    "    description='Live transcribe',\n",
    "    disabled=False,\n",
    "    button_style='info',  # 'success', 'info', 'warning', 'danger' or ''\n",
    "    tooltip='Click to start transcription',\n",
    "    icon='play'\n",
    ")\n",
    "display(start_button)\n",
    "\n",
    "def on_start_button_click(b):\n",
    "    live_transcription()  # Start transcription from mic\n",
    "\n",
    "start_button.on_click(on_start_button_click)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start a radio stream from Internet  \n",
    "(Display will not work on Colab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<audio controls autoplay>\n",
       "  <source src=\"https://timesradio.wireless.radio/stream\" type=\"audio/mpeg\">\n",
       "  Your browser does not support the audio element.\n",
       "</audio>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Audio stream started...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d18c67cfcfde48c1bf6929af888ab30b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Stop Transcription', icon='stop', style=ButtonStyle(), tooltip='Click to stop transcriptio…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Transcript:** The one"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Transcript:** election campaign"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Transcript:** and it was the first one I directed for the Labour Party in 1987. That was a campaign"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Audio stream thread stopping...\n",
      "Finished\n"
     ]
    }
   ],
   "source": [
    "# Times Radio streaming URL\n",
    "URL = 'https://timesradio.wireless.radio/stream'\n",
    "\n",
    "# Create a audio player using HTML for a live stream with autoplay\n",
    "audio_html = f\"\"\"\n",
    "<audio controls autoplay>\n",
    "  <source src=\"{URL}\" type=\"audio/mpeg\">\n",
    "  Your browser does not support the audio element.\n",
    "</audio>\n",
    "\"\"\"\n",
    "\n",
    "display(HTML(audio_html))\n",
    "\n",
    "RADIO_TRANSCRIPT_INTERVAL = 3 # seconds\n",
    "# Start live transcription\n",
    "live_transcription(URL)\n",
    "# It might take a few seconds for the first sentence to appear."
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m125",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m125"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
